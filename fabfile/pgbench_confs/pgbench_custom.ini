[DEFAULT]
postgres_citus_versions: [('12.1', 'release-9.2'), ('12.1', 'release-9.2')]
shard_counts_replication_factors: [(32, 1)]
postgresql_conf: [
                 "max_wal_size = '50GB'",
                 "checkpoint_completion_target = 0.9",
                 "checkpoint_timeout = '1h'",
                 "max_connections = 1000",
                 "max_prepared_transactions = 1000",
                 "citus.multi_shard_commit_protocol = '2pc'"
                 ]

[citus1]
sql_command: CREATE TABLE test_table(a int, b int, c int, d int);
distribute_table_command: SELECT create_distributed_table('test_table', 'a');

[insert_test]
pgbench_command: pgbench -c 32 -j 32 -T 120 -P 5 -n -f fabfile/pgbench_scripts/insert.sql

[update_test]
pgbench_command: pgbench -c 32 -j 32 -T 120 -P 5 -n -f fabfile/pgbench_scripts/update.sql

[delete_test]
pgbench_command: pgbench -c 32 -j 32 -T 120 -P 5 -n -f fabfile/pgbench_scripts/delete.sql

[copy_test]
sql_command: COPY (SELECT generate_series(1,10000), (random() * 32767)::int, (random() * 32767)::int, (random() * 32767)::int) TO '${HOME}/test_data.csv';
pgbench_command: pgbench -c 32 -j 16 -T 120 -P 5 -n -f fabfile/pgbench_scripts/copy.sql-D HOME=${HOME}

[generate_series_test]
pgbench_command: pgbench -c 32 -j 16 -f -T 120 -P 5 -n  fabfile/pgbench_scripts/generate_series.sql
